{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80914446",
   "metadata": {},
   "source": [
    "# Lab Notebook 5-6\n",
    "\n",
    "In this notebook, we will apply the kNN and DT algorithm to a larger exoplanet dataset. We will then examine the effectiveness of the kNN model via a variety of metrics and diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e464a930",
   "metadata": {},
   "source": [
    "# Part 1: Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729fd76",
   "metadata": {},
   "source": [
    "Start by importing the same modules as in labs 3 and 4, set the matplotlib.rc for graphing, and read in **phl_exoplanet_catalog.csv** using pandas. Additionally, with pandas, use set_option to make sure that the maximum number of columns and rows displayed for our dataframes is 100. Also using set_option, set max_colwidth=100, which modifies the default column width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "387cfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ab957",
   "metadata": {},
   "source": [
    "Find a way to print only the column names of the dataframe. These are the data's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77dd13b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./phl_exoplanet_catalog.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24822533",
   "metadata": {},
   "source": [
    "We want to start familiarizing ourselves with our data. Use \"describe()\" on the dataframe to see some summary statistics. Note down what each of these statistics mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "109261f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       P_STATUS        P_MASS  P_MASS_ERROR_MIN  P_MASS_ERROR_MAX  \\\ncount    4048.0   1598.000000       1467.000000       1467.000000   \nmean        3.0    798.384920       -152.292232        190.289692   \nstd         0.0   1406.808654        783.366353       1082.061976   \nmin         3.0      0.019070     -24965.390000          0.000000   \n25%         3.0     26.548968        -79.457001          4.449592   \n50%         3.0    273.332080        -24.154928         25.108412   \n75%         3.0    806.488560         -4.392383         85.813561   \nmax         3.0  17668.059000          0.270000      26630.808000   \n\n          P_RADIUS  P_RADIUS_ERROR_MIN  P_RADIUS_ERROR_MAX       P_YEAR  \\\ncount  3139.000000         3105.000000         3105.000000  4048.000000   \nmean      4.191426           -0.483990            0.621867  2014.212945   \nstd       4.776830            1.409048            2.007592     3.704839   \nmin       0.336300          -54.592700            0.000000  1989.000000   \n25%       1.569400           -0.526870            0.145730  2014.000000   \n50%       2.331680           -0.235410            0.325090  2016.000000   \n75%       3.553570           -0.134520            0.661390  2016.000000   \nmax      77.349000            0.450000           68.919080  2019.000000   \n\n           P_PERIOD  P_PERIOD_ERROR_MIN  ...  S_SNOW_LINE   S_ABIO_ZONE  \\\ncount  3.938000e+03        3.807000e+03  ...  3786.000000  3.083000e+03   \nmean   2.309342e+03       -1.073631e+03  ...     3.513348  1.768991e+35   \nstd    1.167012e+05        5.943181e+04  ...     5.463171  6.944274e+36   \nmin    9.070629e-02       -3.650000e+06  ...     0.002405  7.293660e-05   \n25%    4.497336e+00       -1.129000e-03  ...     1.740762  5.264169e-01   \n50%    1.187053e+01       -9.392000e-05  ...     2.568600  1.429118e+00   \n75%    4.186661e+01       -1.594000e-05  ...     3.661581  2.641037e+00   \nmax    7.300000e+06        3.200000e-02  ...   104.112780  2.726899e+38   \n\n       S_TIDAL_LOCK  P_HABZONE_OPT  P_HABZONE_CON  P_HABITABLE        P_ESI  \\\ncount   3281.000000    4048.000000    4048.000000  4048.000000  3721.000000   \nmean       0.440103       0.049654       0.034091     0.021986     0.261252   \nstd        0.074285       0.217256       0.181485     0.195731     0.131333   \nmin        0.030707       0.000000       0.000000     0.000000     0.006768   \n25%        0.420337       0.000000       0.000000     0.000000     0.196982   \n50%        0.448357       0.000000       0.000000     0.000000     0.271192   \n75%        0.472140       0.000000       0.000000     0.000000     0.303346   \nmax        1.322542       1.000000       1.000000     2.000000     0.931208   \n\n       P_RADIUS_EST    P_MASS_EST  P_SEMI_MAJOR_AXIS_EST  \ncount   4048.000000   4048.000000            3978.000000  \nmean       5.588647    323.089993               4.011385  \nstd        5.392733    965.084290              62.389968  \nmin        0.000000      0.000000               0.004400  \n25%        1.703920      3.628101               0.053000  \n50%        2.667980      7.815324               0.102199  \n75%       11.770500    149.379160               0.260507  \nmax       77.349000  17668.059000            2500.000000  \n\n[8 rows x 98 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P_STATUS</th>\n      <th>P_MASS</th>\n      <th>P_MASS_ERROR_MIN</th>\n      <th>P_MASS_ERROR_MAX</th>\n      <th>P_RADIUS</th>\n      <th>P_RADIUS_ERROR_MIN</th>\n      <th>P_RADIUS_ERROR_MAX</th>\n      <th>P_YEAR</th>\n      <th>P_PERIOD</th>\n      <th>P_PERIOD_ERROR_MIN</th>\n      <th>...</th>\n      <th>S_SNOW_LINE</th>\n      <th>S_ABIO_ZONE</th>\n      <th>S_TIDAL_LOCK</th>\n      <th>P_HABZONE_OPT</th>\n      <th>P_HABZONE_CON</th>\n      <th>P_HABITABLE</th>\n      <th>P_ESI</th>\n      <th>P_RADIUS_EST</th>\n      <th>P_MASS_EST</th>\n      <th>P_SEMI_MAJOR_AXIS_EST</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4048.0</td>\n      <td>1598.000000</td>\n      <td>1467.000000</td>\n      <td>1467.000000</td>\n      <td>3139.000000</td>\n      <td>3105.000000</td>\n      <td>3105.000000</td>\n      <td>4048.000000</td>\n      <td>3.938000e+03</td>\n      <td>3.807000e+03</td>\n      <td>...</td>\n      <td>3786.000000</td>\n      <td>3.083000e+03</td>\n      <td>3281.000000</td>\n      <td>4048.000000</td>\n      <td>4048.000000</td>\n      <td>4048.000000</td>\n      <td>3721.000000</td>\n      <td>4048.000000</td>\n      <td>4048.000000</td>\n      <td>3978.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.0</td>\n      <td>798.384920</td>\n      <td>-152.292232</td>\n      <td>190.289692</td>\n      <td>4.191426</td>\n      <td>-0.483990</td>\n      <td>0.621867</td>\n      <td>2014.212945</td>\n      <td>2.309342e+03</td>\n      <td>-1.073631e+03</td>\n      <td>...</td>\n      <td>3.513348</td>\n      <td>1.768991e+35</td>\n      <td>0.440103</td>\n      <td>0.049654</td>\n      <td>0.034091</td>\n      <td>0.021986</td>\n      <td>0.261252</td>\n      <td>5.588647</td>\n      <td>323.089993</td>\n      <td>4.011385</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>1406.808654</td>\n      <td>783.366353</td>\n      <td>1082.061976</td>\n      <td>4.776830</td>\n      <td>1.409048</td>\n      <td>2.007592</td>\n      <td>3.704839</td>\n      <td>1.167012e+05</td>\n      <td>5.943181e+04</td>\n      <td>...</td>\n      <td>5.463171</td>\n      <td>6.944274e+36</td>\n      <td>0.074285</td>\n      <td>0.217256</td>\n      <td>0.181485</td>\n      <td>0.195731</td>\n      <td>0.131333</td>\n      <td>5.392733</td>\n      <td>965.084290</td>\n      <td>62.389968</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.0</td>\n      <td>0.019070</td>\n      <td>-24965.390000</td>\n      <td>0.000000</td>\n      <td>0.336300</td>\n      <td>-54.592700</td>\n      <td>0.000000</td>\n      <td>1989.000000</td>\n      <td>9.070629e-02</td>\n      <td>-3.650000e+06</td>\n      <td>...</td>\n      <td>0.002405</td>\n      <td>7.293660e-05</td>\n      <td>0.030707</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.006768</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.004400</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3.0</td>\n      <td>26.548968</td>\n      <td>-79.457001</td>\n      <td>4.449592</td>\n      <td>1.569400</td>\n      <td>-0.526870</td>\n      <td>0.145730</td>\n      <td>2014.000000</td>\n      <td>4.497336e+00</td>\n      <td>-1.129000e-03</td>\n      <td>...</td>\n      <td>1.740762</td>\n      <td>5.264169e-01</td>\n      <td>0.420337</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.196982</td>\n      <td>1.703920</td>\n      <td>3.628101</td>\n      <td>0.053000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.0</td>\n      <td>273.332080</td>\n      <td>-24.154928</td>\n      <td>25.108412</td>\n      <td>2.331680</td>\n      <td>-0.235410</td>\n      <td>0.325090</td>\n      <td>2016.000000</td>\n      <td>1.187053e+01</td>\n      <td>-9.392000e-05</td>\n      <td>...</td>\n      <td>2.568600</td>\n      <td>1.429118e+00</td>\n      <td>0.448357</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.271192</td>\n      <td>2.667980</td>\n      <td>7.815324</td>\n      <td>0.102199</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.0</td>\n      <td>806.488560</td>\n      <td>-4.392383</td>\n      <td>85.813561</td>\n      <td>3.553570</td>\n      <td>-0.134520</td>\n      <td>0.661390</td>\n      <td>2016.000000</td>\n      <td>4.186661e+01</td>\n      <td>-1.594000e-05</td>\n      <td>...</td>\n      <td>3.661581</td>\n      <td>2.641037e+00</td>\n      <td>0.472140</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.303346</td>\n      <td>11.770500</td>\n      <td>149.379160</td>\n      <td>0.260507</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.0</td>\n      <td>17668.059000</td>\n      <td>0.270000</td>\n      <td>26630.808000</td>\n      <td>77.349000</td>\n      <td>0.450000</td>\n      <td>68.919080</td>\n      <td>2019.000000</td>\n      <td>7.300000e+06</td>\n      <td>3.200000e-02</td>\n      <td>...</td>\n      <td>104.112780</td>\n      <td>2.726899e+38</td>\n      <td>1.322542</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.931208</td>\n      <td>77.349000</td>\n      <td>17668.059000</td>\n      <td>2500.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 98 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67382085",
   "metadata": {},
   "source": [
    "We can group statistics by class. For each possible value of \"P_HABITABLE\" (0 = not habitable, 1 = possibly habitable, or 2 = probably habitable), display the count for each of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2bfe43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            P_STATUS                                     P_MASS              \\\n               count mean  std  min  25%  50%  75%  max   count        mean   \nP_HABITABLE                                                                   \n0             3993.0  3.0  0.0  3.0  3.0  3.0  3.0  3.0  1575.0  809.993111   \n1               21.0  3.0  0.0  3.0  3.0  3.0  3.0  3.0    16.0    1.941373   \n2               34.0  3.0  0.0  3.0  3.0  3.0  3.0  3.0     7.0    6.984497   \n\n             ...  P_MASS_EST               P_SEMI_MAJOR_AXIS_EST            \\\n             ...         75%           max                 count      mean   \nP_HABITABLE  ...                                                             \n0            ...  156.689210  17668.059000                3923.0  4.063305   \n1            ...    2.545899      3.931532                  21.0  0.169579   \n2            ...    6.584072      8.921432                  34.0  0.393622   \n\n                                                                            \n                   std      min       25%       50%       75%          max  \nP_HABITABLE                                                                 \n0            62.824346  0.00440  0.052847  0.101407  0.259030  2500.000000  \n1             0.197510  0.02144  0.037100  0.089000  0.213000     0.718000  \n2             0.280729  0.09100  0.175235  0.258808  0.589277     1.190229  \n\n[3 rows x 776 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"8\" halign=\"left\">P_STATUS</th>\n      <th colspan=\"2\" halign=\"left\">P_MASS</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">P_MASS_EST</th>\n      <th colspan=\"8\" halign=\"left\">P_SEMI_MAJOR_AXIS_EST</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>...</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>P_HABITABLE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3993.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1575.0</td>\n      <td>809.993111</td>\n      <td>...</td>\n      <td>156.689210</td>\n      <td>17668.059000</td>\n      <td>3923.0</td>\n      <td>4.063305</td>\n      <td>62.824346</td>\n      <td>0.00440</td>\n      <td>0.052847</td>\n      <td>0.101407</td>\n      <td>0.259030</td>\n      <td>2500.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>16.0</td>\n      <td>1.941373</td>\n      <td>...</td>\n      <td>2.545899</td>\n      <td>3.931532</td>\n      <td>21.0</td>\n      <td>0.169579</td>\n      <td>0.197510</td>\n      <td>0.02144</td>\n      <td>0.037100</td>\n      <td>0.089000</td>\n      <td>0.213000</td>\n      <td>0.718000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>6.984497</td>\n      <td>...</td>\n      <td>6.584072</td>\n      <td>8.921432</td>\n      <td>34.0</td>\n      <td>0.393622</td>\n      <td>0.280729</td>\n      <td>0.09100</td>\n      <td>0.175235</td>\n      <td>0.258808</td>\n      <td>0.589277</td>\n      <td>1.190229</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 776 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = df.groupby(\"P_HABITABLE\")\n",
    "grouped_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a8ae8",
   "metadata": {},
   "source": [
    "# Part 2: Modify data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe159912",
   "metadata": {},
   "source": [
    "## Step 2.1\n",
    "\n",
    "We want a binary classification problem, so lump together \"probably\" (P_habitable=2) and \"possibly\" (P_habitable=1) habitable planets in a new dataframe. Check that the two classes are lumped together correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "833c7e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "P_HABITABLE\n0    3993\n1      55\nName: count, dtype: int64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "lumped_df = copy(df)\n",
    "lumped_df['P_HABITABLE'] = lumped_df['P_HABITABLE'].replace(2, 1)\n",
    "\n",
    "# Check that the two classes are lumped together correctly\n",
    "lumped_df['P_HABITABLE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "P_HABITABLE\n0    3993\n2      34\n1      21\nName: count, dtype: int64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P_HABITABLE'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "bcb22d7a",
   "metadata": {},
   "source": [
    "## Step 2.2\n",
    "\n",
    "Let's simplify our data by only using the features 'S_MASS', 'P_PERIOD', and 'P_DISTANCE'. From the dataset created in step 2.1 create a new dataframe called \"final_features\" that is comprised of the columns 'S_MASS', 'P_PERIOD', and 'P_DISTANCE'. Display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d483dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = lumped_df[['S_MASS','P_PERIOD','P_DISTANCE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f047b8",
   "metadata": {},
   "source": [
    "Each column of a data frame is called a *series*. Create a new series named \"targets\" that is the column \"P_HABITABLE\". Display the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29972351",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = lumped_df['P_HABITABLE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ef9da",
   "metadata": {},
   "source": [
    "## Step 2.3\n",
    "\n",
    "We need to delete data points that contain missing (NaN) values. We can see that NaN values exist by comparing the shape of \"final_features\" with the count of non-NaN values (using \"describe\"). Complete these two steps below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "435fc9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4048.0"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a153368",
   "metadata": {},
   "source": [
    "Count the number of NaN values in each column of \"final_features\" (hint: use isnull()). how many are there in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb111762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "S_MASS        765\nP_PERIOD      110\nP_DISTANCE     70\ndtype: int64"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb25027",
   "metadata": {},
   "source": [
    "Remove rows that have one or more NaN values (hint: use \"dropna\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3867af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      S_MASS     P_PERIOD  P_DISTANCE\n0       2.70   326.030000    1.324418\n1       2.78   516.219970    1.534896\n2       2.20   185.840000    0.830000\n3       0.90  1773.400000    3.130558\n4       1.08   798.500000    2.043792\n...      ...          ...         ...\n4043    0.41    28.165600    0.134560\n4044    0.41     7.906961    0.057690\n4045    0.12     3.204000    0.021000\n4046    0.12     6.689000    0.035000\n4047    0.12    13.031000    0.054000\n\n[3180 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S_MASS</th>\n      <th>P_PERIOD</th>\n      <th>P_DISTANCE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.70</td>\n      <td>326.030000</td>\n      <td>1.324418</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.78</td>\n      <td>516.219970</td>\n      <td>1.534896</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.20</td>\n      <td>185.840000</td>\n      <td>0.830000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.90</td>\n      <td>1773.400000</td>\n      <td>3.130558</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.08</td>\n      <td>798.500000</td>\n      <td>2.043792</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4043</th>\n      <td>0.41</td>\n      <td>28.165600</td>\n      <td>0.134560</td>\n    </tr>\n    <tr>\n      <th>4044</th>\n      <td>0.41</td>\n      <td>7.906961</td>\n      <td>0.057690</td>\n    </tr>\n    <tr>\n      <th>4045</th>\n      <td>0.12</td>\n      <td>3.204000</td>\n      <td>0.021000</td>\n    </tr>\n    <tr>\n      <th>4046</th>\n      <td>0.12</td>\n      <td>6.689000</td>\n      <td>0.035000</td>\n    </tr>\n    <tr>\n      <th>4047</th>\n      <td>0.12</td>\n      <td>13.031000</td>\n      <td>0.054000</td>\n    </tr>\n  </tbody>\n</table>\n<p>3180 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897a9c7",
   "metadata": {},
   "source": [
    "## Step 2.4\n",
    "\n",
    "We will now search for outliers in the data and remove them. One quick way to check if there are any is to inspect the distribution of values in each column by creating a histogram. Do this for all three columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a40ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "748c90ab",
   "metadata": {},
   "source": [
    "Due to the wide range of the x-axis (without specifying the range), we can infer that there are outliers. \n",
    "\n",
    "We can also tell that there are outliers when we look at the difference between the mean and median for each of the features. Do this below using \"describe()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b42b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2387162",
   "metadata": {},
   "source": [
    "Time to remove the outliers. \n",
    "\n",
    "With scipy.stats.zscore, you can compute the z-score of \"final_features\". The z-score is the distance between the observed data point and the population mean, scaled by the standard deviation. Keep all data with absolute value of the z-score less than 5 in the array final_features, and remove any data that does not fit this criteria.\n",
    "\n",
    "Make sure that the data kept and removed in \"targets\" reflects this change.\n",
    "\n",
    "Use \"final_features.head(n=10)\" to show the first 10 rows of \"final_features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7a570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dd5d773",
   "metadata": {},
   "source": [
    "As you should see above in \"final_features\" (and \"targets\"), the label for each row is not the true row number. In other words, the row label doesn't increase as 0,1,2,3,...\n",
    "\n",
    "Reset the index of the data frame using \"reset_index(drop=True)\". This resets the index of the DataFrame, and inserts index into the dataframe columns.\n",
    "\n",
    "Do the same for \"targets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19effaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ef1ee",
   "metadata": {},
   "source": [
    "# Part 3: Explore data (again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228242f0",
   "metadata": {},
   "source": [
    "## Step 3.1\n",
    "\n",
    "We want to check the balance of the data set. Meaning, in \"targets\", how many ones versus zeros are there?\n",
    "\n",
    "Print the sum of \"targets\" (sum of all the ones) divided by the length of \"targets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c7848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1925e1",
   "metadata": {},
   "source": [
    "Also, try using \"bincount\" on \"targets\" to show the distribution of ones and zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2ccf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8ceee8",
   "metadata": {},
   "source": [
    "Now we know that the data set is very imbalanced (many more zeros than ones). This means that we need to be careful when constructing our machine learning model; briefly explain why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a315b",
   "metadata": {},
   "source": [
    "## Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ae5474",
   "metadata": {},
   "source": [
    "## Step 3.2\n",
    "\n",
    "Concatenate \"final_features\" and \"targets\" without outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57257584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b30bf71d",
   "metadata": {},
   "source": [
    "Group the data by \"P_HABITABLE\", display make one row for P_HABITABLE=0 and another row for P_HABITABLE=1 and use the .describe() method to display summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef107bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5118beb9",
   "metadata": {},
   "source": [
    "## Step 3.3\n",
    "\n",
    "Plot the period of orbit as a function of the mass of the parent star. It should look like fig 3.1 in our textbook.\n",
    "\n",
    "Make sure your graph:\n",
    "- has a legend (habitable versus not habitable)\n",
    "- is a scatter plot\n",
    "- has data (habitable versus not habitable) differentiated by colour\n",
    "- has a log y-scale\n",
    "- includes axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63865da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75275cc2",
   "metadata": {},
   "source": [
    "# Part 4: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49432a57",
   "metadata": {},
   "source": [
    "## Step 4.1\n",
    "\n",
    "Implement train_test_split features and targets. Fix the random state to 3, You can use the default test size, which is 25%. This process will give you Xtrain, Xtest, ytrain, and ytest. Print the shapes of Xtrain and Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40959c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "970a6668",
   "metadata": {},
   "source": [
    "Create a machine learning model by calling \"KNeighborsClassifier\". Remember that for the kNN algorithm, it is important to standardize the data since it relies on the notion of a metric. To this end, you can use the RobustScaler utility from sklearn.preprocessing. It is also recommended to construct a pipeline with the classifier so that the data is automatically scaled before given to the classifier algorithm. You can use Pipeline from sklearn.pipeline for this. The concept is explained in Chapter 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf57bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65d4a2f5",
   "metadata": {},
   "source": [
    "Let's see how many 1's (\"Habitable\") are predicted by our model. Count the number of ones in ytest, and then compare it to the number of ones in the y-array predicted from Xtest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d495de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b57e14e",
   "metadata": {},
   "source": [
    "Let's check the performance of the classifier. Compute the accuracy, precision and recall scores using the **metrics** package for the test data. Also compute the performance of the \"lazy\" classifier that just assumes y=0 throughout. Any comments? What do these results mean for the success of our classifier? Can we improve our results by modifying the number of nearest neighbours in Step 4.1? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af69cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a115869c",
   "metadata": {},
   "source": [
    "## Step 4.2\n",
    "\n",
    "Now let's plot the result. Use a scatter plot like in Step 3.3. Make sure that the training and testing points are represented by different shapes. Habitable and non-habitable points should be differentiated by colour as before. Label the axes and include a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eafd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6b8e8e1",
   "metadata": {},
   "source": [
    "## Step 4.3\n",
    "Repeat steps 4.1 and 4.2 with the DecisionTreeClassifier, random_state=42. Any comments on the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72dd755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa6f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06fcc0f2",
   "metadata": {},
   "source": [
    "# Part 5: Cross-validation\n",
    "Implement cross-validation on both models for the three metrics accuracy, precision, and recall with stratified k-folds, random shuffling, and 10 splits, random_state=10. What is k-fold validation, and what happens when stratification is applied? Report the mean CV score and the standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5135e5",
   "metadata": {},
   "source": [
    "# Part 6: Confusion Matrix\n",
    "\n",
    "Construct the confusion matrices for the two classifiers from above. Please write code from scratch to compute the matrix elements, but feel free to check it against the function provided by sklearn.metrics. Use **cross_val_predict** to assemble the predictions of several folds. You can then use **ConfusionMatrixDisplay()** to visualize, or write your own plotting routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bdb9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "946eae08",
   "metadata": {},
   "source": [
    "# Part 7: ROC curve\n",
    "Construct the ROC curves for both classifiers. Please use **sklearn's metrics.roc_curve()** to compute the points curve and then plot them. Also draw the ROC curve of a useless (i.e. random) classifier. Don't forget axis labels and a legend. Use cross_val_predict to obtain the probabilities of the predictions. Please also report the ROC AUC score for both classifiers as an average over the 10 folds, using **cross_val_score()**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c491385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "944a2cad",
   "metadata": {},
   "source": [
    "# Part 8: Learning curves\n",
    "\n",
    "With the help of the module **learning_curve** from sklearn.model_selection, construct the learning curves for both classifiers as shown in Fig. 3.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637d792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dae8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943cf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac348d0f",
   "metadata": {},
   "source": [
    "# Part 9: Should we exist?\n",
    "Use the kNN and DT classifiers that you trained above to predict the habitability of the earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3f207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}